{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook I have implementented voice to text recognition on a medical dataset.\n",
    "However due to insufficient audio dataset the 1D convolutional and LSTM models could not be tested for accuracy.\n",
    "This notbook only focuses on the approach taken for voice to text recognition.\n",
    "I have gathered audio files converted them to .WAV format at 8000 sampling rate, MONO channel.\n",
    "Maximum size of the file is 3 sec and the files shorter than that have been padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D, LSTM, BatchNormalization,GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abdominoplasty',\n",
       " 'Acanthamoeba',\n",
       " 'Achondroplasia',\n",
       " 'Addison_Disease',\n",
       " 'Adenocarcinoma',\n",
       " 'Cystic_Fibrosis',\n",
       " 'Diabetes',\n",
       " 'Gastritis',\n",
       " 'Gastroenterostomy',\n",
       " 'Gynecomastia',\n",
       " 'Heartburn',\n",
       " 'Hypertension',\n",
       " 'Jugular_Vein',\n",
       " 'Leucoderma',\n",
       " 'Macular_Degeneration',\n",
       " 'Mean_Corpuscular_Volume',\n",
       " 'Meningitis_Contagious',\n",
       " 'Meningoencephalitis_Toxoplasma',\n",
       " 'Migraine',\n",
       " 'Mitral_Valve_Prolapse',\n",
       " 'Multiple_Sclerosis',\n",
       " 'Ophthalmology',\n",
       " 'Peroneal_muscle',\n",
       " 'Posterior_muscles',\n",
       " 'Pulmonary_artery']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = 'F:/Speech2Text/train_data'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the count of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "recordings=[]\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(path + '/'+ label) if f.endswith('.wav')]\n",
    "    recordings.append(len(waves))\n",
    "print(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the sampling rate of labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    #print(label)\n",
    "    waves = [f for f in os.listdir(path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(path + '/' + label + '/' + wav, sr = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(sample_rate)\n",
    "#print(samples)\n",
    "samples = np.asarray(samples)\n",
    "print(samples.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction.\n",
    "Here Zero padding is done to the audio files who are less than maximum size of the file.\n",
    "Next mfcc mel-freq features across 20 dimensions have been extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sr = 8000\n",
    "hop_length = int(0.5*sr + 2)\n",
    "n_fft = hop_length + int(0.02*sr) #Consider 5ms window around the edges as a buffer/delay\n",
    "#hop_length = n_fft//2\n",
    "all_wave = []\n",
    "all_label = []\n",
    "max_size = 24800\n",
    "for label in labels:\n",
    "    #print(label)\n",
    "    waves = [f for f in os.listdir(path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        samples, sr = librosa.load(path + '/' + label + '/' + wav, sr=8000)\n",
    "        size = samples.shape[0]\n",
    "        \n",
    "        n_pad = max_size - size\n",
    "        samples = np.pad(samples, (0, n_pad), mode='constant')\n",
    "        mfc = librosa.feature.mfcc(y=samples, sr=sr, n_mfcc=20, n_fft=n_fft, hop_length=hop_length).T\n",
    "        #mfc = librosa.feature.mfcc(y=samples, sr=sr, n_mfcc=20).T\n",
    "         \n",
    "        all_wave.append(mfc)\n",
    "        all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "4002\n",
      "4162\n"
     ]
    }
   ],
   "source": [
    "# 24800 / 8000\n",
    "print(sr)\n",
    "print(hop_length)\n",
    "print(n_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 7, 20)\n"
     ]
    }
   ],
   "source": [
    "all_wave = np.array(all_wave)\n",
    "#all_wave = np.asarray(all_wave)\n",
    "print(all_wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "#all_wave = np.expand_dims(all_wave, -1)\n",
    "print(all_wave.dtype)\n",
    "\n",
    "#print(all_wave.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abdominoplasty', 'Acanthamoeba', 'Achondroplasia', 'Addison_Disease', 'Adenocarcinoma', 'Cystic_Fibrosis', 'Diabetes', 'Gastritis', 'Gastroenterostomy', 'Gynecomastia', 'Heartburn', 'Hypertension', 'Jugular_Vein', 'Leucoderma', 'Macular_Degeneration', 'Mean_Corpuscular_Volume', 'Meningitis_Contagious', 'Meningoencephalitis_Toxoplasma', 'Migraine', 'Mitral_Valve_Prolapse', 'Multiple_Sclerosis', 'Ophthalmology', 'Peroneal_muscle', 'Posterior_muscles', 'Pulmonary_artery']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y=le.fit_transform(all_label)\n",
    "classes= list(le.classes_)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "y=utils.to_categorical(y, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(all_wave,y,test_size = 0.2,shuffle=True,random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 7, 20)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_tr.mean(axis=0, keepdims=True)\n",
    "std = x_tr.std(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = (x_tr - mean) / (std + 1e-8)\n",
    "x_val = (x_val - mean) / (std + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 25)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 25)\n"
     ]
    }
   ],
   "source": [
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 7, 20)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(25, input_shape = (x_tr.shape[1:]), activation = \"relu\"))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dense(25, activation = \"relu\"))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(25, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1 = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model1.compile(loss='categorical_crossentropy',optimizer=opt1,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.0790 - accuracy: 0.0500 - val_loss: 3.2553 - val_accuracy: 0.0667\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0528 - accuracy: 0.1500 - val_loss: 3.2556 - val_accuracy: 0.0667\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.9591 - accuracy: 0.1500 - val_loss: 3.2547 - val_accuracy: 0.0667\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0354 - accuracy: 0.0500 - val_loss: 3.2535 - val_accuracy: 0.0667\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.1007 - accuracy: 0.1167 - val_loss: 3.2539 - val_accuracy: 0.0667\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.0652 - accuracy: 0.1000 - val_loss: 3.2527 - val_accuracy: 0.0667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.1139 - accuracy: 0.1333 - val_loss: 3.2517 - val_accuracy: 0.0667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0492 - accuracy: 0.0667 - val_loss: 3.2516 - val_accuracy: 0.0667\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9950 - accuracy: 0.1167 - val_loss: 3.2518 - val_accuracy: 0.0667\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.0075 - accuracy: 0.0667 - val_loss: 3.2522 - val_accuracy: 0.0667\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0920 - accuracy: 0.0500 - val_loss: 3.2516 - val_accuracy: 0.0667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.0740 - accuracy: 0.0500 - val_loss: 3.2510 - val_accuracy: 0.0667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.1124 - accuracy: 0.0833 - val_loss: 3.2515 - val_accuracy: 0.0667\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9972 - accuracy: 0.1000 - val_loss: 3.2510 - val_accuracy: 0.0667\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9897 - accuracy: 0.1500 - val_loss: 3.2527 - val_accuracy: 0.0667\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0770 - accuracy: 0.1000 - val_loss: 3.2544 - val_accuracy: 0.0667\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0160 - accuracy: 0.1333 - val_loss: 3.2530 - val_accuracy: 0.0667\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.1483 - accuracy: 0.0500 - val_loss: 3.2531 - val_accuracy: 0.0667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0137 - accuracy: 0.1667 - val_loss: 3.2536 - val_accuracy: 0.0667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9414 - accuracy: 0.1333 - val_loss: 3.2540 - val_accuracy: 0.0667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0400 - accuracy: 0.0500 - val_loss: 3.2543 - val_accuracy: 0.0667\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9781 - accuracy: 0.1500 - val_loss: 3.2552 - val_accuracy: 0.0667\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0375 - accuracy: 0.0833 - val_loss: 3.2557 - val_accuracy: 0.0667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.9407 - accuracy: 0.1333 - val_loss: 3.2567 - val_accuracy: 0.0667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0203 - accuracy: 0.0833 - val_loss: 3.2562 - val_accuracy: 0.0667\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.8883 - accuracy: 0.1333 - val_loss: 3.2573 - val_accuracy: 0.0667\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.9410 - accuracy: 0.1167 - val_loss: 3.2583 - val_accuracy: 0.0667\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.9772 - accuracy: 0.1167 - val_loss: 3.2582 - val_accuracy: 0.0667\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0307 - accuracy: 0.1000 - val_loss: 3.2596 - val_accuracy: 0.0667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0453 - accuracy: 0.0833 - val_loss: 3.2613 - val_accuracy: 0.0667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.0680 - accuracy: 0.0667 - val_loss: 3.2618 - val_accuracy: 0.0667\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.9608 - accuracy: 0.1000 - val_loss: 3.2619 - val_accuracy: 0.0667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.1085 - accuracy: 0.0667 - val_loss: 3.2629 - val_accuracy: 0.0667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9867 - accuracy: 0.0500 - val_loss: 3.2621 - val_accuracy: 0.0667\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0799 - accuracy: 0.0500 - val_loss: 3.2625 - val_accuracy: 0.0667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.8606 - accuracy: 0.1333 - val_loss: 3.2631 - val_accuracy: 0.0667\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0230 - accuracy: 0.1167 - val_loss: 3.2634 - val_accuracy: 0.0667\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9375 - accuracy: 0.1500 - val_loss: 3.2639 - val_accuracy: 0.0667\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.0270 - accuracy: 0.1000 - val_loss: 3.2634 - val_accuracy: 0.0667\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9713 - accuracy: 0.1167 - val_loss: 3.2638 - val_accuracy: 0.0667\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.0587 - accuracy: 0.1000 - val_loss: 3.2644 - val_accuracy: 0.0667\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.0054 - accuracy: 0.0500 - val_loss: 3.2645 - val_accuracy: 0.0667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0688 - accuracy: 0.0833 - val_loss: 3.2649 - val_accuracy: 0.0667\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9589 - accuracy: 0.1333 - val_loss: 3.2652 - val_accuracy: 0.0667\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.1237 - accuracy: 0.0333 - val_loss: 3.2660 - val_accuracy: 0.0667\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.9117 - accuracy: 0.1500 - val_loss: 3.2677 - val_accuracy: 0.0667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0588 - accuracy: 0.0500 - val_loss: 3.2678 - val_accuracy: 0.0667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0045 - accuracy: 0.0833 - val_loss: 3.2688 - val_accuracy: 0.0667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.0503 - accuracy: 0.0833 - val_loss: 3.2700 - val_accuracy: 0.0667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.0280 - accuracy: 0.1167 - val_loss: 3.2711 - val_accuracy: 0.0667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.0424 - accuracy: 0.0500 - val_loss: 3.2714 - val_accuracy: 0.0667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0417 - accuracy: 0.1167 - val_loss: 3.2716 - val_accuracy: 0.0667\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.0355 - accuracy: 0.0500 - val_loss: 3.2713 - val_accuracy: 0.0667\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.9653 - accuracy: 0.1000 - val_loss: 3.2714 - val_accuracy: 0.0667\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0203 - accuracy: 0.0667 - val_loss: 3.2710 - val_accuracy: 0.0667\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.9970 - accuracy: 0.1000 - val_loss: 3.2699 - val_accuracy: 0.0667\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.9976 - accuracy: 0.1333 - val_loss: 3.2722 - val_accuracy: 0.0667\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.9851 - accuracy: 0.1833 - val_loss: 3.2724 - val_accuracy: 0.0667\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0438 - accuracy: 0.1000 - val_loss: 3.2728 - val_accuracy: 0.0667\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0409 - accuracy: 0.1167 - val_loss: 3.2726 - val_accuracy: 0.0667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.9314 - accuracy: 0.1333 - val_loss: 3.2732 - val_accuracy: 0.0667\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.9998 - accuracy: 0.1167 - val_loss: 3.2739 - val_accuracy: 0.0667\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.9535 - accuracy: 0.1167 - val_loss: 3.2743 - val_accuracy: 0.0667\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0265 - accuracy: 0.1167 - val_loss: 3.2761 - val_accuracy: 0.0667\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9090 - accuracy: 0.2000 - val_loss: 3.2767 - val_accuracy: 0.0667\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9869 - accuracy: 0.1167 - val_loss: 3.2773 - val_accuracy: 0.0667\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.9811 - accuracy: 0.1167 - val_loss: 3.2773 - val_accuracy: 0.0667\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.9526 - accuracy: 0.1333 - val_loss: 3.2773 - val_accuracy: 0.0667\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0702 - accuracy: 0.1167 - val_loss: 3.2784 - val_accuracy: 0.0667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.1358 - accuracy: 0.1000 - val_loss: 3.2785 - val_accuracy: 0.0667\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0032 - accuracy: 0.1500 - val_loss: 3.2773 - val_accuracy: 0.0667\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.8637 - accuracy: 0.1333 - val_loss: 3.2769 - val_accuracy: 0.0667\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.1202 - accuracy: 0.0333 - val_loss: 3.2767 - val_accuracy: 0.0667\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.8967 - accuracy: 0.1333 - val_loss: 3.2772 - val_accuracy: 0.0667\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0376 - accuracy: 0.0833 - val_loss: 3.2783 - val_accuracy: 0.0667\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.9982 - accuracy: 0.1500 - val_loss: 3.2788 - val_accuracy: 0.0667\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9341 - accuracy: 0.1333 - val_loss: 3.2796 - val_accuracy: 0.0667\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.0842 - accuracy: 0.0833 - val_loss: 3.2793 - val_accuracy: 0.0667\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.9687 - accuracy: 0.1000 - val_loss: 3.2801 - val_accuracy: 0.0667\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0328 - accuracy: 0.1167 - val_loss: 3.2807 - val_accuracy: 0.0667\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0339 - accuracy: 0.1167 - val_loss: 3.2808 - val_accuracy: 0.0667\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0720 - accuracy: 0.0667 - val_loss: 3.2810 - val_accuracy: 0.0667\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.9282 - accuracy: 0.0833 - val_loss: 3.2836 - val_accuracy: 0.0667\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.0374 - accuracy: 0.1000 - val_loss: 3.2850 - val_accuracy: 0.0667\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.8720 - accuracy: 0.1833 - val_loss: 3.2854 - val_accuracy: 0.0667\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9562 - accuracy: 0.1167 - val_loss: 3.2856 - val_accuracy: 0.0667\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.9915 - accuracy: 0.1333 - val_loss: 3.2864 - val_accuracy: 0.0667\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9707 - accuracy: 0.0833 - val_loss: 3.2860 - val_accuracy: 0.0667\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.8555 - accuracy: 0.1833 - val_loss: 3.2855 - val_accuracy: 0.0667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.0403 - accuracy: 0.1333 - val_loss: 3.2873 - val_accuracy: 0.0667\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.9745 - accuracy: 0.1500 - val_loss: 3.2884 - val_accuracy: 0.0667\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.9704 - accuracy: 0.1167 - val_loss: 3.2875 - val_accuracy: 0.0667\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.0724 - accuracy: 0.1000 - val_loss: 3.2868 - val_accuracy: 0.0667\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.9340 - accuracy: 0.1000 - val_loss: 3.2868 - val_accuracy: 0.0667\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.9052 - accuracy: 0.0833 - val_loss: 3.2872 - val_accuracy: 0.0667\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.0727 - accuracy: 0.0500 - val_loss: 3.2873 - val_accuracy: 0.0667\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.9652 - accuracy: 0.1500 - val_loss: 3.2878 - val_accuracy: 0.0667\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.9724 - accuracy: 0.1167 - val_loss: 3.2877 - val_accuracy: 0.0667\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.9540 - accuracy: 0.0833 - val_loss: 3.2890 - val_accuracy: 0.0667\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.0281 - accuracy: 0.1333 - val_loss: 3.2898 - val_accuracy: 0.0667\n"
     ]
    }
   ],
   "source": [
    "history1=model1.fit(x_tr, y_tr ,epochs=100,batch_size=32, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see the accurracy of the data is not increasing due to insufficient data. The basic requirememnt of the neural nets\n",
    "is they require large amount of data to learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions using LSTM\n",
    "def predict(audio):\n",
    "    prob=model1.predict(np.expand_dims(audio, 1))\n",
    "    index=np.argmax(prob[0])\n",
    "    print(index)\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Audio: Adenocarcinoma\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "index=random.randint(0,len(x_val)-1)\n",
    "print(index)\n",
    "samples=x_val[index]\n",
    "#print(samples)\n",
    "print(\"Audio:\",classes[np.argmax(y_val[index])])\n",
    "#ipd.Audio(samples, rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 311, 20) for input Tensor(\"lstm_1_input:0\", shape=(None, 311, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1, 20).\n",
      "13\n",
      "Text: Leucoderma\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\",predict(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7, 20)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7, 16)             656       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 3, 16)             272       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                425       \n",
      "=================================================================\n",
      "Total params: 1,625\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "#1D Convolutional Neural Net\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(7,20))\n",
    "\n",
    "#First Conv1D layer\n",
    "conv = Conv1D(16, 2, padding='same', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(2)(conv)\n",
    "# conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Second Conv1D layer\n",
    "conv = Conv1D(16, 1, padding='same', activation='relu', strides=1)(conv)\n",
    "conv = GlobalMaxPool1D()(conv)\n",
    "# conv = Dropout(0.3)(conv)\n",
    "\n",
    "\n",
    "#Flatten layer\n",
    "# conv = Flatten()(conv)\n",
    "\n",
    "#Dense Layer 1\n",
    "# conv = Dropout(0.5)(conv)\n",
    "conv = Dense(16, activation='relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n",
    "outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = keras.optimizers.Adam(learning_rate= 1e-3)\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 3.7904 - accuracy: 0.0667 - val_loss: 3.5185 - val_accuracy: 0.0667\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5327 - accuracy: 0.0167 - val_loss: 3.4258 - val_accuracy: 0.0667\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5023 - accuracy: 0.0500 - val_loss: 3.3468 - val_accuracy: 0.0667\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3873 - accuracy: 0.0333 - val_loss: 3.2970 - val_accuracy: 0.0667\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3205 - accuracy: 0.0833 - val_loss: 3.2616 - val_accuracy: 0.0667\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.2338 - accuracy: 0.0667 - val_loss: 3.2445 - val_accuracy: 0.0667\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.2801 - accuracy: 0.0833 - val_loss: 3.2368 - val_accuracy: 0.0667\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.2470 - accuracy: 0.0500 - val_loss: 3.2285 - val_accuracy: 0.0667\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.2020 - accuracy: 0.0667 - val_loss: 3.2209 - val_accuracy: 0.0667\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1687 - accuracy: 0.0833 - val_loss: 3.2165 - val_accuracy: 0.0667\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1383 - accuracy: 0.1167 - val_loss: 3.2101 - val_accuracy: 0.0667\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.1503 - accuracy: 0.0833 - val_loss: 3.2110 - val_accuracy: 0.0667\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.1078 - accuracy: 0.0667 - val_loss: 3.2110 - val_accuracy: 0.0667\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0406 - accuracy: 0.1000 - val_loss: 3.2131 - val_accuracy: 0.0667\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0893 - accuracy: 0.1000 - val_loss: 3.2170 - val_accuracy: 0.0667\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0378 - accuracy: 0.0667 - val_loss: 3.2232 - val_accuracy: 0.0667\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0796 - accuracy: 0.0833 - val_loss: 3.2243 - val_accuracy: 0.0667\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0643 - accuracy: 0.0667 - val_loss: 3.2250 - val_accuracy: 0.1333\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.0554 - accuracy: 0.1333 - val_loss: 3.2294 - val_accuracy: 0.1333\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0908 - accuracy: 0.0833 - val_loss: 3.2386 - val_accuracy: 0.1333\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.0517 - accuracy: 0.0500 - val_loss: 3.2449 - val_accuracy: 0.1333\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9845 - accuracy: 0.1833 - val_loss: 3.2574 - val_accuracy: 0.1333\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.0422 - accuracy: 0.1333 - val_loss: 3.2754 - val_accuracy: 0.1333\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9932 - accuracy: 0.0833 - val_loss: 3.2899 - val_accuracy: 0.1333\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9517 - accuracy: 0.1333 - val_loss: 3.3010 - val_accuracy: 0.1333\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9318 - accuracy: 0.1500 - val_loss: 3.3182 - val_accuracy: 0.0667\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9404 - accuracy: 0.1333 - val_loss: 3.3548 - val_accuracy: 0.0667\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0384 - accuracy: 0.0833 - val_loss: 3.3770 - val_accuracy: 0.0667\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9501 - accuracy: 0.1333 - val_loss: 3.3918 - val_accuracy: 0.0667\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9029 - accuracy: 0.1667 - val_loss: 3.4089 - val_accuracy: 0.1333\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.8669 - accuracy: 0.1667 - val_loss: 3.4164 - val_accuracy: 0.1333\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9121 - accuracy: 0.1000 - val_loss: 3.4359 - val_accuracy: 0.0667\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.9357 - accuracy: 0.0667 - val_loss: 3.4526 - val_accuracy: 0.1333\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9267 - accuracy: 0.1667 - val_loss: 3.4678 - val_accuracy: 0.1333\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.8959 - accuracy: 0.1667 - val_loss: 3.4641 - val_accuracy: 0.0667\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.8220 - accuracy: 0.1833 - val_loss: 3.4817 - val_accuracy: 0.0667\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.8109 - accuracy: 0.1833 - val_loss: 3.5113 - val_accuracy: 0.0667\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9007 - accuracy: 0.1500 - val_loss: 3.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7681 - accuracy: 0.1500 - val_loss: 3.5178 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7495 - accuracy: 0.1167 - val_loss: 3.5691 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6968 - accuracy: 0.1667 - val_loss: 3.6042 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.7386 - accuracy: 0.2167 - val_loss: 3.6437 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7308 - accuracy: 0.1333 - val_loss: 3.6790 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.7668 - accuracy: 0.1667 - val_loss: 3.7052 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6958 - accuracy: 0.1833 - val_loss: 3.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6976 - accuracy: 0.1667 - val_loss: 3.7518 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7014 - accuracy: 0.2000 - val_loss: 3.7964 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6908 - accuracy: 0.2167 - val_loss: 3.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6264 - accuracy: 0.2500 - val_loss: 3.8510 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.7131 - accuracy: 0.1833 - val_loss: 3.8399 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.5451 - accuracy: 0.2000 - val_loss: 3.8171 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6433 - accuracy: 0.1833 - val_loss: 3.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6481 - accuracy: 0.2167 - val_loss: 3.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.5640 - accuracy: 0.2000 - val_loss: 3.9564 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6529 - accuracy: 0.1500 - val_loss: 3.9841 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6152 - accuracy: 0.1500 - val_loss: 3.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4959 - accuracy: 0.2333 - val_loss: 4.0004 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4716 - accuracy: 0.3000 - val_loss: 4.0636 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.5611 - accuracy: 0.2333 - val_loss: 4.1213 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6301 - accuracy: 0.2000 - val_loss: 4.1547 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.5094 - accuracy: 0.2500 - val_loss: 4.1639 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4718 - accuracy: 0.2000 - val_loss: 4.1870 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.5770 - accuracy: 0.1833 - val_loss: 4.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4841 - accuracy: 0.2000 - val_loss: 4.1944 - val_accuracy: 0.0667\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6417 - accuracy: 0.1500 - val_loss: 4.2370 - val_accuracy: 0.0667\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4528 - accuracy: 0.2000 - val_loss: 4.3010 - val_accuracy: 0.0667\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4100 - accuracy: 0.2500 - val_loss: 4.3601 - val_accuracy: 0.0667\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.5225 - accuracy: 0.2167 - val_loss: 4.4084 - val_accuracy: 0.0667\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.3630 - accuracy: 0.2667 - val_loss: 4.4571 - val_accuracy: 0.0667\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2607 - accuracy: 0.3667 - val_loss: 4.4919 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4352 - accuracy: 0.2667 - val_loss: 4.5096 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4097 - accuracy: 0.2667 - val_loss: 4.5159 - val_accuracy: 0.0667\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4297 - accuracy: 0.3000 - val_loss: 4.4800 - val_accuracy: 0.0667\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2849 - accuracy: 0.3000 - val_loss: 4.4934 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.3145 - accuracy: 0.2167 - val_loss: 4.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4349 - accuracy: 0.2333 - val_loss: 4.5280 - val_accuracy: 0.0667\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.3442 - accuracy: 0.2667 - val_loss: 4.5569 - val_accuracy: 0.1333\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.3356 - accuracy: 0.2667 - val_loss: 4.6116 - val_accuracy: 0.1333\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2828 - accuracy: 0.2667 - val_loss: 4.6473 - val_accuracy: 0.1333\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.2122 - accuracy: 0.37 - 0s 5ms/step - loss: 2.2862 - accuracy: 0.2333 - val_loss: 4.7155 - val_accuracy: 0.1333\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4435 - accuracy: 0.2667 - val_loss: 4.7473 - val_accuracy: 0.1333\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.2561 - accuracy: 0.25 - 0s 5ms/step - loss: 2.2380 - accuracy: 0.2833 - val_loss: 4.7740 - val_accuracy: 0.0667\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.3413 - accuracy: 0.2500 - val_loss: 4.8012 - val_accuracy: 0.0667\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2812 - accuracy: 0.2667 - val_loss: 4.8336 - val_accuracy: 0.0667\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.1699 - accuracy: 0.3167 - val_loss: 4.9045 - val_accuracy: 0.0667\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3700 - accuracy: 0.2167 - val_loss: 4.9492 - val_accuracy: 0.0667\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2068 - accuracy: 0.3500 - val_loss: 4.9635 - val_accuracy: 0.0667\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0962 - accuracy: 0.3667 - val_loss: 4.9901 - val_accuracy: 0.0667\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2584 - accuracy: 0.2500 - val_loss: 5.0348 - val_accuracy: 0.0667\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.1707 - accuracy: 0.3500 - val_loss: 5.1055 - val_accuracy: 0.0667\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2033 - accuracy: 0.3000 - val_loss: 5.1721 - val_accuracy: 0.0667\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0125 - accuracy: 0.3500 - val_loss: 5.2509 - val_accuracy: 0.0667\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2589 - accuracy: 0.1500 - val_loss: 5.2668 - val_accuracy: 0.0667\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.3351 - accuracy: 0.2667 - val_loss: 5.2444 - val_accuracy: 0.0667\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0620 - accuracy: 0.4500 - val_loss: 5.2297 - val_accuracy: 0.0667\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.9906 - accuracy: 0.4000 - val_loss: 5.2526 - val_accuracy: 0.0667\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2489 - accuracy: 0.2333 - val_loss: 5.3305 - val_accuracy: 0.0667\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0644 - accuracy: 0.3000 - val_loss: 5.3796 - val_accuracy: 0.0667\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2155 - accuracy: 0.2833 - val_loss: 5.4528 - val_accuracy: 0.0667\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1331 - accuracy: 0.3167 - val_loss: 5.4891 - val_accuracy: 0.0667\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.2178 - accuracy: 0.2833 - val_loss: 5.5048 - val_accuracy: 0.0667\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.1240 - accuracy: 0.3000 - val_loss: 5.5508 - val_accuracy: 0.0667\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1405 - accuracy: 0.3833 - val_loss: 5.6028 - val_accuracy: 0.0667\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.0024 - accuracy: 0.3000 - val_loss: 5.5586 - val_accuracy: 0.0667\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.0905 - accuracy: 0.3833 - val_loss: 5.5925 - val_accuracy: 0.0667\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0486 - accuracy: 0.3667 - val_loss: 5.6738 - val_accuracy: 0.0667\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.1070 - accuracy: 0.3000 - val_loss: 5.7707 - val_accuracy: 0.0667\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0538 - accuracy: 0.3833 - val_loss: 5.7909 - val_accuracy: 0.0667\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0210 - accuracy: 0.3667 - val_loss: 5.8376 - val_accuracy: 0.0667\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9152 - accuracy: 0.4000 - val_loss: 5.8384 - val_accuracy: 0.0667\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0328 - accuracy: 0.3167 - val_loss: 5.8985 - val_accuracy: 0.0667\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9337 - accuracy: 0.3500 - val_loss: 5.9244 - val_accuracy: 0.0667\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7829 - accuracy: 0.4167 - val_loss: 5.9720 - val_accuracy: 0.0667\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9450 - accuracy: 0.4000 - val_loss: 6.0359 - val_accuracy: 0.0667\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.8497 - accuracy: 0.4333 - val_loss: 6.0902 - val_accuracy: 0.0667\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1168 - accuracy: 0.2833 - val_loss: 6.1117 - val_accuracy: 0.0667\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.9873 - accuracy: 0.3500 - val_loss: 6.1919 - val_accuracy: 0.0667\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8900 - accuracy: 0.3833 - val_loss: 6.2399 - val_accuracy: 0.0667\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0344 - accuracy: 0.3333 - val_loss: 6.2190 - val_accuracy: 0.0667\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8252 - accuracy: 0.4667 - val_loss: 6.2341 - val_accuracy: 0.0667\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7423 - accuracy: 0.4500 - val_loss: 6.2521 - val_accuracy: 0.0667\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8831 - accuracy: 0.4000 - val_loss: 6.2617 - val_accuracy: 0.0667\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7860 - accuracy: 0.4000 - val_loss: 6.2766 - val_accuracy: 0.0667\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8047 - accuracy: 0.4500 - val_loss: 6.2908 - val_accuracy: 0.0667\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7485 - accuracy: 0.3667 - val_loss: 6.3617 - val_accuracy: 0.0667\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7389 - accuracy: 0.4667 - val_loss: 6.5139 - val_accuracy: 0.0667\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8368 - accuracy: 0.4000 - val_loss: 6.5879 - val_accuracy: 0.0667\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7721 - accuracy: 0.4333 - val_loss: 6.5939 - val_accuracy: 0.0667\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8569 - accuracy: 0.3500 - val_loss: 6.6420 - val_accuracy: 0.0667\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6608 - accuracy: 0.4667 - val_loss: 6.7630 - val_accuracy: 0.0667\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8717 - accuracy: 0.3833 - val_loss: 6.8508 - val_accuracy: 0.0667\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8027 - accuracy: 0.4667 - val_loss: 6.8192 - val_accuracy: 0.0667\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6888 - accuracy: 0.5333 - val_loss: 6.8435 - val_accuracy: 0.0667\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6211 - accuracy: 0.4667 - val_loss: 6.8414 - val_accuracy: 0.0667\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7639 - accuracy: 0.3833 - val_loss: 6.8822 - val_accuracy: 0.0667\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8485 - accuracy: 0.4333 - val_loss: 6.8589 - val_accuracy: 0.0667\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6624 - accuracy: 0.5000 - val_loss: 6.9257 - val_accuracy: 0.0667\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6847 - accuracy: 0.3667 - val_loss: 7.0353 - val_accuracy: 0.0667\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8237 - accuracy: 0.3667 - val_loss: 7.0504 - val_accuracy: 0.0667\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.9073 - accuracy: 0.3833 - val_loss: 7.1261 - val_accuracy: 0.0667\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8088 - accuracy: 0.4000 - val_loss: 7.1257 - val_accuracy: 0.0667\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7385 - accuracy: 0.4167 - val_loss: 7.1445 - val_accuracy: 0.0667\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6456 - accuracy: 0.5000 - val_loss: 7.2160 - val_accuracy: 0.0667\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7179 - accuracy: 0.3667 - val_loss: 7.2676 - val_accuracy: 0.0667\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5906 - accuracy: 0.4833 - val_loss: 7.2338 - val_accuracy: 0.0667\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8641 - accuracy: 0.3833 - val_loss: 7.1848 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6888 - accuracy: 0.4667 - val_loss: 7.1976 - val_accuracy: 0.0667\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8807 - accuracy: 0.3500 - val_loss: 7.1995 - val_accuracy: 0.0667\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8160 - accuracy: 0.3833 - val_loss: 7.2764 - val_accuracy: 0.0667\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6996 - accuracy: 0.3667 - val_loss: 7.3733 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7064 - accuracy: 0.4167 - val_loss: 7.3579 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8199 - accuracy: 0.3833 - val_loss: 7.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.5987 - accuracy: 0.4667 - val_loss: 7.5051 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5290 - accuracy: 0.5500 - val_loss: 7.5337 - val_accuracy: 0.0667\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6167 - accuracy: 0.4833 - val_loss: 7.6041 - val_accuracy: 0.0667\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6450 - accuracy: 0.5000 - val_loss: 7.6376 - val_accuracy: 0.0667\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6076 - accuracy: 0.4000 - val_loss: 7.7066 - val_accuracy: 0.0667\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6279 - accuracy: 0.5167 - val_loss: 7.6688 - val_accuracy: 0.0667\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6317 - accuracy: 0.4667 - val_loss: 7.7237 - val_accuracy: 0.0667\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6388 - accuracy: 0.4167 - val_loss: 7.8417 - val_accuracy: 0.0667\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6001 - accuracy: 0.4333 - val_loss: 7.8880 - val_accuracy: 0.0667\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5301 - accuracy: 0.5000 - val_loss: 7.8414 - val_accuracy: 0.0667\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4725 - accuracy: 0.5833 - val_loss: 7.7863 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4744 - accuracy: 0.5000 - val_loss: 7.7511 - val_accuracy: 0.0667\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4892 - accuracy: 0.5667 - val_loss: 7.8157 - val_accuracy: 0.0667\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6844 - accuracy: 0.4833 - val_loss: 7.8729 - val_accuracy: 0.0667\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6189 - accuracy: 0.4833 - val_loss: 7.9341 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7379 - accuracy: 0.3000 - val_loss: 8.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.5649 - accuracy: 0.4333 - val_loss: 8.0084 - val_accuracy: 0.0667\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4385 - accuracy: 0.5500 - val_loss: 7.9751 - val_accuracy: 0.0667\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5802 - accuracy: 0.4833 - val_loss: 8.0791 - val_accuracy: 0.0667\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7660 - accuracy: 0.3333 - val_loss: 8.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5434 - accuracy: 0.4833 - val_loss: 8.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4974 - accuracy: 0.4667 - val_loss: 8.4214 - val_accuracy: 0.0667\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5755 - accuracy: 0.5000 - val_loss: 8.3355 - val_accuracy: 0.0667\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5908 - accuracy: 0.5000 - val_loss: 8.2889 - val_accuracy: 0.0667\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2630 - accuracy: 0.5833 - val_loss: 8.2917 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2695 - accuracy: 0.5333 - val_loss: 8.3256 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3764 - accuracy: 0.5667 - val_loss: 8.3966 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4840 - accuracy: 0.4667 - val_loss: 8.5143 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2457 - accuracy: 0.5833 - val_loss: 8.5718 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4500 - accuracy: 0.5000 - val_loss: 8.6434 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4048 - accuracy: 0.5500 - val_loss: 8.7111 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3367 - accuracy: 0.5667 - val_loss: 8.8945 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3036 - accuracy: 0.5667 - val_loss: 9.0266 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5837 - accuracy: 0.4500 - val_loss: 8.9380 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4858 - accuracy: 0.5333 - val_loss: 8.8361 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6024 - accuracy: 0.4167 - val_loss: 8.7836 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4183 - accuracy: 0.5833 - val_loss: 8.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4421 - accuracy: 0.4500 - val_loss: 8.9735 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3078 - accuracy: 0.6333 - val_loss: 9.0607 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6246 - accuracy: 0.4000 - val_loss: 9.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4878 - accuracy: 0.4500 - val_loss: 9.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3824 - accuracy: 0.5500 - val_loss: 9.0575 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4125 - accuracy: 0.4667 - val_loss: 9.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4179 - accuracy: 0.5333 - val_loss: 9.0769 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4372 - accuracy: 0.4667 - val_loss: 9.1854 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5221 - accuracy: 0.4833 - val_loss: 9.2612 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2625 - accuracy: 0.5500 - val_loss: 9.2879 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2775 - accuracy: 0.6000 - val_loss: 9.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6344 - accuracy: 0.4000 - val_loss: 9.3989 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1229 - accuracy: 0.6333 - val_loss: 9.3185 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4699 - accuracy: 0.5167 - val_loss: 9.4778 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4633 - accuracy: 0.4833 - val_loss: 9.5569 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4497 - accuracy: 0.5000 - val_loss: 9.6322 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2364 - accuracy: 0.6000 - val_loss: 9.6769 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2096 - accuracy: 0.6333 - val_loss: 9.7486 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3030 - accuracy: 0.5833 - val_loss: 9.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3077 - accuracy: 0.5333 - val_loss: 9.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3679 - accuracy: 0.5333 - val_loss: 9.7251 - val_accuracy: 0.0667\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5181 - accuracy: 0.4167 - val_loss: 9.5948 - val_accuracy: 0.0667\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3559 - accuracy: 0.5167 - val_loss: 9.5704 - val_accuracy: 0.0667\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3409 - accuracy: 0.5500 - val_loss: 9.6803 - val_accuracy: 0.0667\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3191 - accuracy: 0.5000 - val_loss: 9.6824 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3347 - accuracy: 0.5500 - val_loss: 9.6957 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4610 - accuracy: 0.5500 - val_loss: 9.8466 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2637 - accuracy: 0.5500 - val_loss: 9.9390 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2842 - accuracy: 0.5667 - val_loss: 9.9341 - val_accuracy: 0.0667\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2405 - accuracy: 0.5667 - val_loss: 9.9853 - val_accuracy: 0.0667\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3372 - accuracy: 0.4667 - val_loss: 10.0545 - val_accuracy: 0.0667\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3413 - accuracy: 0.5167 - val_loss: 10.1390 - val_accuracy: 0.0667\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3378 - accuracy: 0.4833 - val_loss: 10.2568 - val_accuracy: 0.0667\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4271 - accuracy: 0.4167 - val_loss: 10.2057 - val_accuracy: 0.0667\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2354 - accuracy: 0.5500 - val_loss: 10.1124 - val_accuracy: 0.0667\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3206 - accuracy: 0.4833 - val_loss: 10.1036 - val_accuracy: 0.0667\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3841 - accuracy: 0.4833 - val_loss: 10.0747 - val_accuracy: 0.0667\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4962 - accuracy: 0.4667 - val_loss: 10.1199 - val_accuracy: 0.0667\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5500 - val_loss: 10.1768 - val_accuracy: 0.0667\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2794 - accuracy: 0.5500 - val_loss: 10.2381 - val_accuracy: 0.0667\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4652 - accuracy: 0.4667 - val_loss: 10.3143 - val_accuracy: 0.0667\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2564 - accuracy: 0.5833 - val_loss: 10.3209 - val_accuracy: 0.0667\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4861 - accuracy: 0.5167 - val_loss: 10.3431 - val_accuracy: 0.0667\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2937 - accuracy: 0.5333 - val_loss: 10.3793 - val_accuracy: 0.0667\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3085 - accuracy: 0.5167 - val_loss: 10.3469 - val_accuracy: 0.0667\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2861 - accuracy: 0.5667 - val_loss: 10.2778 - val_accuracy: 0.0667\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3567 - accuracy: 0.5333 - val_loss: 10.3379 - val_accuracy: 0.0667\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1245 - accuracy: 0.6333 - val_loss: 10.3278 - val_accuracy: 0.0667\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2502 - accuracy: 0.5333 - val_loss: 10.3539 - val_accuracy: 0.0667\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4566 - accuracy: 0.4833 - val_loss: 10.5640 - val_accuracy: 0.0667\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1588 - accuracy: 0.5833 - val_loss: 10.8168 - val_accuracy: 0.0667\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1906 - accuracy: 0.6167 - val_loss: 10.7144 - val_accuracy: 0.0667\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9826 - accuracy: 0.6667 - val_loss: 10.7101 - val_accuracy: 0.0667\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3228 - accuracy: 0.5667 - val_loss: 10.6698 - val_accuracy: 0.0667\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3082 - accuracy: 0.6000 - val_loss: 10.6051 - val_accuracy: 0.0667\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2293 - accuracy: 0.5333 - val_loss: 10.6874 - val_accuracy: 0.0667\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3552 - accuracy: 0.5500 - val_loss: 10.7461 - val_accuracy: 0.0667\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4365 - accuracy: 0.4833 - val_loss: 10.8250 - val_accuracy: 0.0667\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3340 - accuracy: 0.5000 - val_loss: 10.8806 - val_accuracy: 0.0667\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4581 - accuracy: 0.4667 - val_loss: 10.8835 - val_accuracy: 0.0667\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2531 - accuracy: 0.4833 - val_loss: 10.9642 - val_accuracy: 0.0667\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3299 - accuracy: 0.5833 - val_loss: 11.0801 - val_accuracy: 0.0667\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9749 - accuracy: 0.7333 - val_loss: 11.2617 - val_accuracy: 0.0667\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0638 - accuracy: 0.6000 - val_loss: 11.3341 - val_accuracy: 0.0667\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2005 - accuracy: 0.5667 - val_loss: 11.3519 - val_accuracy: 0.0667\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2948 - accuracy: 0.5333 - val_loss: 11.3494 - val_accuracy: 0.0667\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2546 - accuracy: 0.5667 - val_loss: 11.3584 - val_accuracy: 0.0667\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3436 - accuracy: 0.4833 - val_loss: 11.5428 - val_accuracy: 0.0667\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2530 - accuracy: 0.5333 - val_loss: 11.6117 - val_accuracy: 0.0667\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3720 - accuracy: 0.5833 - val_loss: 11.7013 - val_accuracy: 0.0667\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0824 - accuracy: 0.6500 - val_loss: 11.6781 - val_accuracy: 0.0667\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2437 - accuracy: 0.5500 - val_loss: 11.6673 - val_accuracy: 0.0667\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0922 - accuracy: 0.6500 - val_loss: 11.7217 - val_accuracy: 0.0667\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2001 - accuracy: 0.5667 - val_loss: 11.8152 - val_accuracy: 0.0667\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2754 - accuracy: 0.5333 - val_loss: 11.8460 - val_accuracy: 0.0667\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3121 - accuracy: 0.5833 - val_loss: 11.7531 - val_accuracy: 0.0667\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1393 - accuracy: 0.5667 - val_loss: 11.7307 - val_accuracy: 0.0667\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3671 - accuracy: 0.4833 - val_loss: 11.7048 - val_accuracy: 0.0667\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9974 - accuracy: 0.7000 - val_loss: 11.8076 - val_accuracy: 0.0667\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3429 - accuracy: 0.5167 - val_loss: 11.8027 - val_accuracy: 0.0667\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1619 - accuracy: 0.5500 - val_loss: 11.7315 - val_accuracy: 0.0667\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2270 - accuracy: 0.4667 - val_loss: 11.8910 - val_accuracy: 0.0667\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3098 - accuracy: 0.5167 - val_loss: 12.0103 - val_accuracy: 0.0667\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1522 - accuracy: 0.5833 - val_loss: 12.0965 - val_accuracy: 0.0667\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1153 - accuracy: 0.6167 - val_loss: 12.1366 - val_accuracy: 0.0667\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0625 - accuracy: 0.6833 - val_loss: 12.1362 - val_accuracy: 0.0667\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0819 - accuracy: 0.5667 - val_loss: 12.2036 - val_accuracy: 0.0667\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2870 - accuracy: 0.5667 - val_loss: 12.1745 - val_accuracy: 0.0667\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0263 - accuracy: 0.6667 - val_loss: 12.1438 - val_accuracy: 0.0667\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2931 - accuracy: 0.5000 - val_loss: 12.0670 - val_accuracy: 0.0667\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2866 - accuracy: 0.6000 - val_loss: 12.0678 - val_accuracy: 0.0667\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9182 - accuracy: 0.6667 - val_loss: 11.9533 - val_accuracy: 0.0667\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4261 - accuracy: 0.4667 - val_loss: 11.9250 - val_accuracy: 0.0667\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2274 - accuracy: 0.5000 - val_loss: 12.0441 - val_accuracy: 0.0667\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2447 - accuracy: 0.4667 - val_loss: 12.2081 - val_accuracy: 0.0667\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1099 - accuracy: 0.6333 - val_loss: 12.3647 - val_accuracy: 0.0667\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2514 - accuracy: 0.5500 - val_loss: 12.4633 - val_accuracy: 0.0667\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0816 - accuracy: 0.6000 - val_loss: 12.5094 - val_accuracy: 0.0667\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2144 - accuracy: 0.5500 - val_loss: 12.3383 - val_accuracy: 0.0667\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2873 - accuracy: 0.5167 - val_loss: 12.3076 - val_accuracy: 0.0667\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0950 - accuracy: 0.6000 - val_loss: 12.3947 - val_accuracy: 0.0667\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1970 - accuracy: 0.6000 - val_loss: 12.5323 - val_accuracy: 0.0667\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3095 - accuracy: 0.5000 - val_loss: 12.6447 - val_accuracy: 0.0667\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0527 - accuracy: 0.6333 - val_loss: 12.7862 - val_accuracy: 0.0667\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2840 - accuracy: 0.4833 - val_loss: 12.8935 - val_accuracy: 0.0667\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3138 - accuracy: 0.5167 - val_loss: 12.9190 - val_accuracy: 0.0667\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1194 - accuracy: 0.5667 - val_loss: 12.9386 - val_accuracy: 0.0667\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9132 - accuracy: 0.7167 - val_loss: 13.0020 - val_accuracy: 0.0667\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1159 - accuracy: 0.5500 - val_loss: 13.0963 - val_accuracy: 0.0667\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1858 - accuracy: 0.6167 - val_loss: 13.0632 - val_accuracy: 0.0667\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2682 - accuracy: 0.5333 - val_loss: 13.0170 - val_accuracy: 0.0667\n"
     ]
    }
   ],
   "source": [
    "#history=model.fit(x_tr, y_tr ,epochs=300,batch_size=8, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Downloading sounddevice-0.4.0-py3.cp32.cp33.cp34.cp35.cp36.cp37.cp38.cp39.pp32.pp33.pp34.pp35.pp36.pp37-none-win_amd64.whl (167 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sounddevice) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.20)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.10.3.post1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from soundfile) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prompt for users to record voice commands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "samplerate = 8000  \n",
    "duration = 3 # seconds\n",
    "filename = 'migrane.wav'\n",
    "print(\"start\")\n",
    "mydata = sd.rec(int(samplerate * duration), samplerate=samplerate,\n",
    "    channels=1, blocking=True)\n",
    "print(\"end\")\n",
    "sd.wait()\n",
    "sf.write(filename, mydata, samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
